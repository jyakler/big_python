{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\BigData\\PYDATAexam\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available kernels:\n",
      "  pydatavenv    C:\\Users\\JY_Kim\\AppData\\Roaming\\jupyter\\kernels\\pydatavenv\n",
      "  python3       D:\\anaconda\\share\\jupyter\\kernels\\python3\n"
     ]
    }
   ],
   "source": [
    "!jupyter kernelspec list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " C 드라이브의 볼륨에는 이름이 없습니다.\n",
      " 볼륨 일련 번호: 646D-1932\n",
      "\n",
      " C:\\BigData\\PYDATAexam 디렉터리\n",
      "\n",
      "2022-04-15  오후 03:08    <DIR>          .\n",
      "2022-04-15  오후 03:08    <DIR>          ..\n",
      "2022-04-15  오전 10:49    <DIR>          .ipynb_checkpoints\n",
      "2022-04-15  오전 10:52            45,179 exam0.ipynb\n",
      "2022-04-15  오전 10:45            24,966 exam1.ipynb\n",
      "2022-04-15  오전 11:36               977 first.ipynb\n",
      "2022-04-15  오후 03:08               789 second.ipynb\n",
      "               4개 파일              71,911 바이트\n",
      "               3개 디렉터리  40,276,078,592 바이트 남음\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'http.client.HTTPResponse'>\n",
      "200\n",
      "11\n",
      "OK\n",
      "[ header 정보 ]----------\n",
      "('Server', 'NWS')\n",
      "('Date', 'Fri, 15 Apr 2022 06:13:01 GMT')\n",
      "('Content-Type', 'text/html; charset=UTF-8')\n",
      "('Transfer-Encoding', 'chunked')\n",
      "('Connection', 'close')\n",
      "('Set-Cookie', 'PM_CK_loc=37a57d5d17f8a26937fa7c3b06be0920e97aa5ddca408ef6c3a4fab0e37cbc34; Expires=Sat, 16 Apr 2022 06:13:01 GMT; Path=/; HttpOnly')\n",
      "('Cache-Control', 'no-cache, no-store, must-revalidate')\n",
      "('Pragma', 'no-cache')\n",
      "('P3P', 'CP=\"CAO DSP CURa ADMa TAIa PSAa OUR LAW STP PHY ONL UNI PUR FIN COM NAV INT DEM STA PRE\"')\n",
      "('X-Frame-Options', 'DENY')\n",
      "('X-XSS-Protection', '1; mode=block')\n",
      "('Strict-Transport-Security', 'max-age=63072000; includeSubdomains')\n",
      "('Referrer-Policy', 'unsafe-url')\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "res = urllib.request.urlopen(\"http://www.naver.com/\")\n",
    "print(type(res))\n",
    "print(res.status)\n",
    "print(res.version)\n",
    "print(res.msg)\n",
    "res_header = res.getheaders()\n",
    "print(\"[ header 정보 ]----------\")\n",
    "for s in res_header :\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<http.client.HTTPResponse object at 0x0000026219886E20>\n",
      "[ header 정보 ]----------\n",
      "('Date', 'Fri, 15 Apr 2022 06:23:48 GMT')\n",
      "('Server', 'Apache/2.2.15 (CentOS)')\n",
      "('Content-Length', '461')\n",
      "('Connection', 'close')\n",
      "('Content-Type', 'text/html')\n",
      "[ body 내용 ]-----------\n",
      "<!DOCTYPE html>\n",
      "<html>\n",
      "<head>\n",
      "<meta charset=\"UTF-8\">\n",
      "<title>Insert title here</title>\n",
      "</head>\n",
      "<body>\n",
      "<h1>블럭스타일 태그</h1>\n",
      "<div style=\"background-color:yellow\">테스트입니다1</div>\n",
      "<div>테스트입니다2</div>\n",
      "<div>테스트입니다3</div>\n",
      "<hr>\n",
      "<h1>인라인스타일 태그</h1>\n",
      "<span style=\"background-color:yellow\">테스트입니다1</span>\n",
      "<span>테스트입니다2</span>\n",
      "<span>테스트입니다3</span>\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "res = urllib.request.urlopen(\"http://unico2013.dothome.co.kr/crawling/tagstyle.html\")\n",
    "print(res)\n",
    "print(\"[ header 정보 ]----------\")\n",
    "res_header = res.getheaders()\n",
    "for s in res_header :\n",
    "    print(s)\n",
    "print(\"[ body 내용 ]-----------\")\n",
    "#print(res.read()) # 바이트 문자열, 바이트열 - b'..............'\n",
    "print(res.read().decode('utf-8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================\n",
      "<class 'http.client.HTTPResponse'>\n",
      "<class 'http.client.HTTPMessage'>\n",
      "https://www.python.org/  페이지의 인코딩 정보 : utf-8\n",
      "<!doctype html>\n",
      "<!--[if lt IE 7]>   <html class=\"no-js ie6 lt-ie7 lt-ie8 lt-ie9\">   <![endif]-->\n",
      "<!--[if IE 7]>      <html class=\"no-js ie7 lt-ie8 lt-ie9\">          <![endif]-->\n",
      "<!--[if IE 8]>      <html class=\"no-js ie8 lt-ie9\">                 <![endif]-->\n",
      "<!--[if gt IE 8]><!--><html class=\"no-js\" lang=\"en\" dir=\"ltr\">  <!--<![endif]-->\n",
      "\n",
      "<head>\n",
      "    <meta charset=\"utf-8\">\n",
      "    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n",
      "\n",
      "    <link rel=\"prefetch\" href=\"//ajax.googleapis.com/ajax/libs/jqu\n",
      "===========================================================\n",
      "https://www.daum.net/  페이지의 인코딩 정보 : utf-8\n",
      "<!DOCTYPE html><html lang=\"ko\"> <head> <meta charset=\"utf-8\" /> <title>Daum</title> <meta http-equiv=\"x-ua-compatible\" content=\"IE=edge\" /> <meta property=\"og:url\" content=\"//www.daum.net/\" /> <meta property=\"og:type\" content=\"website\" /> <meta property=\"og:title\" content=\"Daum\" /> <meta http-equiv=\"Pragma\" content=\"no-cache\" /> <meta http-equiv=\"Expires\" content=\"-1\" /> <meta name=\"referrer\" content=\"origin\" /> <meta property=\"og:image\" content=\"https://i1.daumcdn.net/svc/image/U03/common_icon/\n",
      "===========================================================\n",
      "http://www.yes24.com/Main/default.aspx  페이지의 인코딩 정보 : ks_c_5601-1987\n",
      "\n",
      "\t<!DOCTYPE html>\n",
      "\t<html lang=\"ko\">\n",
      "\n",
      "<head>\n",
      "\t<meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge\" />\n",
      "\t<meta http-equiv=\"Content-Type\" content=\"text/html;charset=euc-kr\" />\n",
      "\t<meta http-equiv=\"Accept-CH\" content=\"dpr, width, viewport-width, rtt, downlink, ect, UA, UA-Platform, UA-Arch, UA-Model, UA-Mobile, UA-Full-Version\" />\n",
      "\t<meta http-equiv=\"Accept-CH-Lifetime\" content=\"86400\" />\n",
      "\t<meta name=\"referrer\" content=\"unsafe-url\" />\n",
      "\t<meta name=\"viewport\" content=\"width=1170\" />\n",
      "\n",
      "\t<title>Y\n",
      "===========================================================\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "print(\"===========================================================\")\n",
    "url = 'https://www.python.org/'\n",
    "f = urllib.request.urlopen(url)\n",
    "print(type(f))\n",
    "print(type(f.info()))\n",
    "encoding = f.info().get_content_charset()\n",
    "encoding = 'utf-8' if encoding == None else encoding\n",
    "print(url, ' 페이지의 인코딩 정보 :', encoding)\n",
    "text = f.read(500).decode(encoding)\n",
    "print(text)\n",
    "print(\"===========================================================\")\n",
    "\n",
    "url = 'https://www.daum.net/'\n",
    "f = urllib.request.urlopen(url)\n",
    "encoding = f.info().get_content_charset() \n",
    "encoding = 'utf-8' if encoding == None else encoding\n",
    "print(url, ' 페이지의 인코딩 정보 :', encoding)\n",
    "text = f.read(500).decode(encoding)\n",
    "print(text)\n",
    "print(\"===========================================================\")\n",
    "\n",
    "url = 'http://www.yes24.com/Main/default.aspx'\n",
    "f = urllib.request.urlopen(url)\n",
    "encoding = f.info().get_content_charset()\n",
    "encoding = 'utf-8' if encoding == None else encoding\n",
    "print(url, ' 페이지의 인코딩 정보 :', encoding)\n",
    "\n",
    "text = f.read(500).decode(encoding)\n",
    "print(text)\n",
    "print(\"===========================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ URL 문자열 정보 추출 1 ]\n",
      "타입정보 :  <class 'urllib.parse.ParseResult'>\n",
      "도메인정보 :  movie.daum.net\n",
      "패스정보 :  /moviedb/main\n",
      "쿼리정보 :  movieId=93252\n",
      "스킴정보 :  https\n",
      "포트정보 :  None\n",
      "프래그먼트정보 :  \n",
      "URL 문자열정보 :  https://movie.daum.net/moviedb/main?movieId=93252\n",
      "urllib.parse.ParseResult 객체정보 :  ParseResult(scheme='https', netloc='movie.daum.net', path='/moviedb/main', params='', query='movieId=93252', fragment='')\n",
      "\n",
      "[ URL 문자열 정보 추출 2 ]\n",
      "도메인정보 :  docs.python.org\n",
      "패스정보 :  /3/library/urllib.parse.html\n",
      "쿼리정보 :  \n",
      "스킴정보 :  https\n",
      "포트정보 :  None\n",
      "프래그먼트정보 :  urlparse-result-object\n",
      "URL 문자열정보 :  https://docs.python.org/3/library/urllib.parse.html#urlparse-result-object\n",
      "urllib.parse.ParseResult 객체정보 :  ParseResult(scheme='https', netloc='docs.python.org', path='/3/library/urllib.parse.html', params='', query='', fragment='urlparse-result-object')\n",
      "\n",
      "[ Query문자열 또는 요청 파라미터 인코딩 ]\n",
      "number=12524&type=issue&action=show\n",
      "addr=%EC%84%9C%EC%9A%B8%EC%8B%9C+%EA%B0%95%EB%82%A8%EA%B5%AC+%EC%97%AD%EC%82%BC%EB%8F%99\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urlparse\n",
    "from urllib.parse import urlencode\n",
    "print(\"[ URL 문자열 정보 추출 1 ]\")\n",
    "url1 = urlparse('https://movie.daum.net/moviedb/main?movieId=93252')\n",
    "print(\"타입정보 : \",type(url1))\n",
    "print(\"도메인정보 : \",url1.netloc) \n",
    "print(\"패스정보 : \",url1.path)\n",
    "print(\"쿼리정보 : \",url1.query) \n",
    "print(\"스킴정보 : \",url1.scheme)\n",
    "print(\"포트정보 : \",url1.port)\n",
    "print(\"프래그먼트정보 : \",url1.fragment)\n",
    "print(\"URL 문자열정보 : \",url1.geturl())\n",
    "print(\"urllib.parse.ParseResult 객체정보 : \",url1)\n",
    "print(\"\\n[ URL 문자열 정보 추출 2 ]\")\n",
    "url2 = urlparse('https://docs.python.org/3/library/urllib.parse.html#urlparse-result-object')\n",
    "print(\"도메인정보 : \",url2.netloc) \n",
    "print(\"패스정보 : \", url2.path)  \n",
    "print(\"쿼리정보 : \",url2.query)\n",
    "print(\"스킴정보 : \",url2.scheme)\n",
    "print(\"포트정보 : \",url2.port)\n",
    "print(\"프래그먼트정보 : \",url2.fragment)\n",
    "print(\"URL 문자열정보 : \",url2.geturl())\n",
    "print(\"urllib.parse.ParseResult 객체정보 : \",url2)\n",
    "\n",
    "print(\"\\n[ Query문자열 또는 요청 파라미터 인코딩 ]\")\n",
    "params1 = urlencode({'number': 12524, 'type': 'issue', 'action': 'show'})\n",
    "print(params1)\n",
    "params2 = urlencode({'addr': '서울시 강남구 역삼동'})\n",
    "print(params2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL 인코딩 규칙이 적용된 문자열 : name=%EC%9C%A0%EB%8B%88%EC%BD%94&age=10\n",
      "﻿<!DOCTYPE html>\n",
      "<html>\n",
      "  <head>\n",
      "    <meta charset=\"utf-8\">\n",
      "    <title>POST TEST</title>\n",
      "  </head>\n",
      "  <body>\n",
      "   <h1>GET : 이름은 유니코이고 나이는 10이네요!!</h1>   </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import urllib.parse\n",
    "params = urllib.parse.urlencode({'name': '유니코', 'age': 10})\n",
    "print(\"URL 인코딩 규칙이 적용된 문자열 : %s\" % params)\n",
    "url = \"http://unico2013.dothome.co.kr/crawling/get.php?%s\" % params\n",
    "with urllib.request.urlopen(url) as f:\n",
    "    print(f.read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL 인코딩 규칙이 적용된 문자열 : name=%EC%9C%A0%EB%8B%88%EC%BD%94&age=10\n",
      "변환된 바이트 문자열 : b'name=%EC%9C%A0%EB%8B%88%EC%BD%94&age=10'\n",
      "﻿<!DOCTYPE html>\n",
      "<html>\n",
      "  <head>\n",
      "    <meta charset=\"utf-8\">\n",
      "    <title>POST TEST</title>\n",
      "  </head>\n",
      "  <body>\n",
      "   <h1>POST : 이름은 유니코이고 나이는 10이네요!!</h1>   </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import urllib.parse\n",
    "data = urllib.parse.urlencode({'name': '유니코', 'age': 10})\n",
    "print(\"URL 인코딩 규칙이 적용된 문자열 : %s\" % data)\n",
    "postdata = data.encode('ascii')\n",
    "print(\"변환된 바이트 문자열 : %s\" % postdata)\n",
    "url = \"http://unico2013.dothome.co.kr/crawling/post.php\"\n",
    "with urllib.request.urlopen(url, postdata) as f:\n",
    "    print(f.read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<urllib.request.Request object at 0x00000262198DBBE0>\n",
      "﻿<!DOCTYPE html>\n",
      "<html>\n",
      "  <head>\n",
      "    <meta charset=\"utf-8\">\n",
      "    <title>POST TEST</title>\n",
      "  </head>\n",
      "  <body>\n",
      "   <h1>POST : 이름은 유니코이고 나이는 10이네요!!</h1>   </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import urllib.parse\n",
    "data = urllib.parse.urlencode({'name': '유니코', 'age': 10})\n",
    "postdata = data.encode('ascii')\n",
    "req = urllib.request.Request(url='http://unico2013.dothome.co.kr/crawling/post.php',\n",
    "            data=postdata)\n",
    "print(req)\n",
    "with urllib.request.urlopen(req) as f:\n",
    "    print(f.read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'requests.models.Response'>\n",
      "<!DOCTYPE html>\n",
      "<html>\n",
      "<head>\n",
      "<meta charset=\"UTF-8\">\n",
      "<title>테스트</title>\n",
      "</head>\n",
      "<body>\n",
      "<h1>웹 크롤링을 테스트 합니다.</h1>\n",
      "</body>\n",
      "</html>\n",
      "----------------------------------------------------------\n",
      "<class 'requests.models.Response'>\n",
      "응답된 콘텐츠가 없어요\n",
      "----------------------------------------------------------\n",
      "<class 'requests.models.Response'>\n",
      "﻿<!DOCTYPE html>\n",
      "<html>\n",
      "  <head>\n",
      "    <meta charset=\"utf-8\">\n",
      "    <title>POST TEST</title>\n",
      "  </head>\n",
      "  <body>\n",
      "   <h1>POST : 이름은 백도이고 나이는 12이네요!!</h1>   </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "r = requests.request('get', 'http://unico2013.dothome.co.kr/crawling/exam.html')\n",
    "r.encoding = 'utf-8'\n",
    "print(type(r))\n",
    "if r.text :\n",
    "    print(r.text)\n",
    "else :\n",
    "    print('응답된 콘텐츠가 없어요')\n",
    "print('----------------------------------------------------------')\n",
    "r = requests.request('head', 'http://unico2013.dothome.co.kr/crawling/exam.html')\n",
    "r.encoding = 'utf-8'\n",
    "print(type(r))\n",
    "if r.text :\n",
    "    print(r.text)\n",
    "else :\n",
    "    print('응답된 콘텐츠가 없어요')\n",
    "print('----------------------------------------------------------')\n",
    "r = requests.request('post', 'http://unico2013.dothome.co.kr/crawling/post.php', data= {'name':'백도', 'age' : 12})\n",
    "r.encoding = 'utf-8'\n",
    "print(type(r))\n",
    "if r.text :\n",
    "    print(r.text)\n",
    "else :\n",
    "    print('응답된 콘텐츠가 없어요')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "r = requests.get('http://unico2013.dothome.co.kr/crawling/exam.html')\n",
    "r.encoding = 'utf-8'\n",
    "print(type(r))\n",
    "print(r.headers)\n",
    "if r.text :\n",
    "    print(r.text)\n",
    "else :\n",
    "    print('응답된 콘텐츠가 없어요')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'requests.models.Response'>\n",
      "{'Date': 'Fri, 15 Apr 2022 07:17:47 GMT', 'Server': 'Apache/2.2.15 (CentOS)', 'Connection': 'close', 'Content-Type': 'text/html'}\n",
      "응답된 콘텐츠가 없어요\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "r = requests.head('http://unico2013.dothome.co.kr/crawling/exam.html')\n",
    "print(type(r))\n",
    "print(r.headers)\n",
    "if r.text :\n",
    "    print(r.text)\n",
    "else :\n",
    "    print('응답된 콘텐츠가 없어요')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://unico2013.dothome.co.kr/crawling/get.php?key1=value1&key2=value2\n",
      "------------------------------------\n",
      "http://unico2013.dothome.co.kr/crawling/get.php?key1=value1&key2=value2&key2=value3\n",
      "------------------------------------\n",
      "http://unico2013.dothome.co.kr/crawling/get.php?key1=value1&key1=value2\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "dicdata = {'key1': 'value1', 'key2': 'value2'}\n",
    "urlstr = 'http://unico2013.dothome.co.kr/crawling/get.php'\n",
    "r = requests.get(urlstr, params=dicdata)\n",
    "print(r.url)\n",
    "print('------------------------------------')\n",
    "dicdata = {'key1': 'value1', 'key2': ['value2', 'value3']}\n",
    "r = requests.request('GET', urlstr, params=dicdata)\n",
    "print(r.url)\n",
    "print('------------------------------------')\n",
    "tupledata = [('key1', 'value1'), ('key1', 'value2')]\n",
    "r = requests.get(urlstr, params=tupledata)\n",
    "print(r.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿<!DOCTYPE html>\n",
      "<html>\n",
      "  <head>\n",
      "    <meta charset=\"utf-8\">\n",
      "    <title>POST TEST</title>\n",
      "  </head>\n",
      "  <body>\n",
      "   <h1>GET : ì´ë¦ê³¼ ëì´ë¥¼ ì ë¬í´ ì£¼ì¸ì!!</h1>   </body>\n",
      "</html>\n",
      "------------------------------------\n",
      "﻿<!DOCTYPE html>\n",
      "<html>\n",
      "  <head>\n",
      "    <meta charset=\"utf-8\">\n",
      "    <title>POST TEST</title>\n",
      "  </head>\n",
      "  <body>\n",
      "   <h1>GET : 이름과 나이를 전달해 주세요!!</h1>   </body>\n",
      "</html>\n",
      "------------------------------------\n",
      "b'\\xef\\xbb\\xbf<!DOCTYPE html>\\r\\n<html>\\r\\n  <head>\\r\\n    <meta charset=\"utf-8\">\\r\\n    <title>POST TEST</title>\\r\\n  </head>\\r\\n  <body>\\r\\n   <h1>GET : \\xec\\x9d\\xb4\\xeb\\xa6\\x84\\xea\\xb3\\xbc \\xeb\\x82\\x98\\xec\\x9d\\xb4\\xeb\\xa5\\xbc \\xec\\xa0\\x84\\xeb\\x8b\\xac\\xed\\x95\\xb4 \\xec\\xa3\\xbc\\xec\\x84\\xb8\\xec\\x9a\\x94!!</h1>   </body>\\r\\n</html>'\n",
      "------------------------------------\n",
      "﻿<!DOCTYPE html>\n",
      "<html>\n",
      "  <head>\n",
      "    <meta charset=\"utf-8\">\n",
      "    <title>POST TEST</title>\n",
      "  </head>\n",
      "  <body>\n",
      "   <h1>GET : 이름과 나이를 전달해 주세요!!</h1>   </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "urlstr = 'http://unico2013.dothome.co.kr/crawling/get.php'\n",
    "r = requests.get(urlstr)\n",
    "print(r.text)\n",
    "print('------------------------------------')\n",
    "r.encoding = 'utf-8'\n",
    "print(r.text)\n",
    "print('------------------------------------')\n",
    "print(r.content)\n",
    "print('------------------------------------')\n",
    "print(r.content.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.JpegImagePlugin.JpegImageFile'>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "r = requests.get('http://unico2013.dothome.co.kr/image/flower.jpg')\n",
    "i = Image.open(BytesIO(r.content))\n",
    "print(type(i))\n",
    "i.save(\"c:/Temp/test.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_doc = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "    <head>\n",
    "        <meta charset=\"utf-8\">\n",
    "        <title>Test BeautifulSoup</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>테스트</h1>\n",
    "    </body>\n",
    "</html> \"\"\"\n",
    "from bs4 import BeautifulSoup\n",
    "bs = BeautifulSoup(html_doc, 'html.parser')\n",
    "print(type(bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_doc = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "     <head>\n",
    "          <meta charset='utf-8'>\n",
    "          <title>Test BeautifulSoup</title>\n",
    "     </head>\n",
    "     <body>\n",
    "          <p align=\"center\">P태그의 컨텐트</p>\n",
    "          <img src=\"http://unico2013.dothome.co.kr/image/flower.jpg\" width=\"300\">\n",
    "     </body>\n",
    "</html> \"\"\"\n",
    "from bs4 import BeautifulSoup\n",
    "bs = BeautifulSoup(html_doc, 'html.parser')\n",
    "print(bs.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_doc = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "     <head>\n",
    "          <meta charset='utf-8'>\n",
    "          <title>Test BeautifulSoup</title>\n",
    "     </head>\n",
    "     <body>\n",
    "          <p align=\"center\">P태그의 컨텐트</p>\n",
    "          <img src=\"http://unico2013.dothome.co.kr/image/flower.jpg\" width=\"300\">\n",
    "          <ul>\n",
    "               <li>테스트1<strong>강조</strong></li>\n",
    "               <li>테스트2</li>\n",
    "               <li>테스트3</li>\n",
    "          </ul>\n",
    "     </body>\n",
    "</html> \"\"\"\n",
    "from bs4 import BeautifulSoup\n",
    "bs = BeautifulSoup(html_doc, 'html.parser')\n",
    "print(type(bs.title), ':', bs.title)\n",
    "print(type(bs.title.name), ':', bs.title.name)\n",
    "print(type(bs.title.string), ':', bs.title.string)\n",
    "print('-------------------------')\n",
    "print(type(bs.p['align']), ':', bs.p['align'])\n",
    "print(type(bs.img['src']), ':', bs.img['src'])\n",
    "print(type(bs.img.attrs), ':', bs.img.attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_doc = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "     <head>\n",
    "          <meta charset='utf-8'>\n",
    "          <title>Test BeautifulSoup</title>\n",
    "     </head>\n",
    "     <body>\n",
    "          <p align=\"center\">P태그의 컨텐트</p>\n",
    "          <img src=\"http://unico2013.dothome.co.kr/image/flower.jpg\" width=\"300\">\n",
    "          <ul>\n",
    "               <li>테스트1<strong>강조</strong></li>\n",
    "               <li>테스트2</li>\n",
    "               <li>테스트3</li>\n",
    "          </ul>\n",
    "     </body>\n",
    "</html> \"\"\"\n",
    "from bs4 import BeautifulSoup\n",
    "bs = BeautifulSoup(html_doc, 'html.parser')\n",
    "print(\"[[[ string 속성 ]]]\")\n",
    "print(type(bs.p.string), ':', bs.p.string)\n",
    "print(type(bs.ul.string), ':', bs.ul.string)\n",
    "print(type(bs.ul.li.string), ':', bs.ul.li.string)\n",
    "print(type(bs.ul.li.strong.string), ':', bs.ul.li.strong.string)\n",
    "print(\"[[[ text 속성 ]]]\")\n",
    "print(type(bs.p.text), ':', bs.p.text)\n",
    "print(type(bs.ul.text), ':', bs.ul.text)\n",
    "print(type(bs.ul.li.text), ':', bs.ul.li.text)\n",
    "print(type(bs.ul.li.strong.text), ':', bs.ul.li.strong.text)\n",
    "print(\"[[[ contents 속성 ]]]\")\n",
    "print(type(bs.p.contents), ':', bs.p.contents)\n",
    "print(type(bs.ul.contents), ':', bs.ul.contents)\n",
    "print(type(bs.ul.li.contents), ':', bs.ul.li.contents)\n",
    "print(type(bs.ul.li.strong.contents), ':', bs.ul.li.strong.contents)\n",
    "print(\"[[[ find_all()의 text=True 매개변수 ]]]\")\n",
    "print(bs.find_all(\"li\", text=True))  # 콘텐츠가 텍스트로만 구성된"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_doc=\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "  <head>\n",
    "     <meta charset='utf-8'>\n",
    "     <title>Test BeautifulSoup</title>\n",
    "  </head>\n",
    "  <body>\n",
    "     <p align=\"center\"> text contents </p>\n",
    "     <p align=\"right\">  text contents 2 </p>\n",
    "     <p align=\"left\">   text contents 3 </p>\n",
    "     <img src=\"http://unico2013.dothome.co.kr/image/flower.jpg\" width=\"500\">\n",
    "     <div>\n",
    "       <p>text contents 4</p> \n",
    "     </div>\n",
    "  </body>\n",
    "</html> \"\"\"\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "bs = BeautifulSoup(html_doc, 'html.parser')\n",
    "print(type(bs.find('p')))\n",
    "print(type(bs.find_all('p')))\n",
    "print(\"---------------------------------\")\n",
    "print(bs.find('title'))\n",
    "print(bs.find('p'))\n",
    "print(bs.find('img'))\n",
    "print(\"---------------------------------\")\n",
    "ptags = bs.find_all('p')\n",
    "print(ptags)\n",
    "print(\"----------------\")\n",
    "for tag in ptags :\n",
    "    print(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html=\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "  <head>\n",
    "     <meta charset='utf-8'>\n",
    "     <title>Test BeautifulSoup</title>\n",
    "  </head>\n",
    "  <body>\n",
    "     <p align=\"center\"> text contents </p>\n",
    "     <p align=\"right\" class=\"myp\">  text contents 2 </p>\n",
    "     <p align=\"left\" a=\"b\">   text contents 3 </p>\n",
    "     <img src=\"http://unico2013.dothome.co.kr/image/flower.jpg\" width=\"500\">\n",
    "  </body>\n",
    "</html> \"\"\"\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "bs = BeautifulSoup(html, 'html.parser')\n",
    "print(bs.find('p', align=\"center\"))\n",
    "print(bs.find('p', class_=\"myp\"))\n",
    "print(bs.find('p', align=\"left\"))\n",
    "print(\"-------------------------------------\")\n",
    "print(bs.find('p', attrs={\"align\":\"center\"}))\n",
    "print(bs.find('p', attrs={\"align\":\"right\", \"class\":\"myp\"}))\n",
    "print(bs.find('p', attrs={\"align\":\"left\"}))\n",
    "\n",
    "pdom = bs.find('p', align=\"left\")\n",
    "print(\"[\"+pdom.text+\"]\")\n",
    "print(\"[\"+pdom.get_text(strip=True)+\"]\")\n",
    "print(\"[\"+pdom.string.strip()+\"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "req = requests.get('http://unico2013.dothome.co.kr/crawling/exercise_css.html')\n",
    "html = req.content\n",
    "print(type(html))\n",
    "html = html.decode('utf-8')\n",
    "#print(html)\n",
    "print(\"==============================\")\n",
    "bs = BeautifulSoup(html, 'html.parser')\n",
    "title = bs.select('h1')\n",
    "title1 = bs.select('#f_subtitle')\n",
    "title2 = bs.select('.subtitle')\n",
    "title3 = bs.select('aside > h2')\n",
    "img = bs.select('[src]')\n",
    "print(title)\n",
    "print(type(title))\n",
    "print(type(title[0]))\n",
    "print(\"<h1>태그의 갯수 : %d \" %len(title))\n",
    "print(\"f_subtitle이라는 id 속성을 갖는 태그 갯수 : %d \" %len(title1))\n",
    "print(\"subtitle이라는 class 속성을 갖는 태그 갯수 : %d \" %len(title2))\n",
    "print(\"aside 태그의 <h2> 자식 태그 갯수 : %d \" %len(title3))\n",
    "print(\"src 속성을 갖는 태그 갯수 : %d \" %len(img))\n",
    "\n",
    "for content in title:\n",
    "    print(content.string)\n",
    "print(\"------------------------------\")\n",
    "for content in title1:\n",
    "    print(content.text)\n",
    "print(\"------------------------------\")\n",
    "for content in title2:\n",
    "    print(content.text)\n",
    "print(\"------------------------------\")\n",
    "for content in title3:\n",
    "    print(content.text)\n",
    "print(\"------------------------------\")\n",
    "for content in img:\n",
    "   print(content[\"src\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "req = requests.get('http://movie.naver.com/movie/point/af/list.nhn?page=1')\n",
    "html = req.text\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "titles = soup.select('.movie')\n",
    "points = soup.select('td.title > div > em')\n",
    "reviews = soup.select('td.title')\n",
    "movie_title = []\n",
    "movie_point = []\n",
    "movie_review = [] \n",
    "\n",
    "for dom in titles:\n",
    "    movie_title.append(dom.text)\n",
    "for dom in points:\n",
    "    movie_point.append(dom.text)\n",
    "for dom in reviews:\n",
    "    content = dom.contents[6] \n",
    "    #content=re.sub(\"신고\", '', content)\n",
    "    content=re.sub(\"[\\n\\t]\", '', content)    \n",
    "    movie_review.append(content)\n",
    "commentLength = len(movie_title)   \n",
    "for i in range(commentLength):\n",
    "    print(\"영화 제목 : \" + movie_title[i])\n",
    "    print(\"평점 : \" + movie_point[i])\n",
    "    print(\"리뷰글 : \" + movie_review[i])\n",
    "    print(\"-----------------------------------------\")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "for n in range(1,31):\n",
    "    req = requests.get('http://movie.naver.com/movie/point/af/list.nhn?page='+str(n))\n",
    "    html = req.text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    titles = soup.select('.movie' )\n",
    "    points = soup.select('td.title > div > em')\n",
    "    reviews = soup.select('td.title')\n",
    "    movie_title = []\n",
    "    movie_point = []\n",
    "    movie_review = [] \n",
    "    for dom in titles:\n",
    "        movie_title.append(dom.text)\n",
    "    for dom in points:\n",
    "        movie_point.append(dom.text)\n",
    "    for dom in reviews:\n",
    "        content = dom.contents[6]\n",
    "        content=re.sub(\"[\\n\\t]\", '', content)\n",
    "        movie_review.append(content)\n",
    "\n",
    "    commentLength = len(movie_title)   \n",
    "    for i in range(commentLength):\n",
    "        print(movie_point[i] + \",\"+movie_title[i]+\",\"+movie_review[i])\n",
    "    print(\"-----------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reviews[0].contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "title = []\n",
    "link = []\n",
    "urlstr = 'http://www.yes24.com/SearchCorner/Search?domain=BOOK&query=python'\n",
    "r = requests.get(urlstr)\n",
    "#r.encoding = \"utf-8\"\n",
    "bs = BeautifulSoup(r.text, 'html.parser')\n",
    "bookList = bs.select('a.gd_name')\n",
    "\n",
    "for bookDom in bookList:\n",
    "    title.append(bookDom.string)\n",
    "    link.append(bookDom[\"href\"])\n",
    "\n",
    "print(\"-- 도서 제목 --\")\n",
    "print(title)\n",
    "print(\"-- 도서 링크 URL --\")\n",
    "print(link)\n",
    "with open('output/booklink.csv', \"wt\", encoding=\"utf-8\") as f:\n",
    "    f.write('booktitle,booklink\\n')  \n",
    "    for i in range(len(title)):\n",
    "        f.write(title[i]+\",\"+link[i]+'\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "import io\n",
    "\n",
    "url = \"http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp?stnId=108\"\n",
    "savename = \"C:/Temp/forecast.xml\"\n",
    "req.urlretrieve(url, savename)\n",
    "\n",
    "xml = open(savename, \"r\", encoding=\"utf-8\").read()\n",
    "soup = BeautifulSoup(xml, 'html.parser') # lxml\n",
    "\n",
    "info = {}\n",
    "for location in soup.find_all(\"location\"):\n",
    "    loc = location.find('city').string\n",
    "    min_w = location.find_all('tmn')\n",
    "    max_w = location.find_all('tmx')\n",
    "    weather = [a.string+\"~\"+b.string for a, b in zip(min_w, max_w)]\n",
    "\n",
    "    if not (loc in info):\n",
    "        info[loc] = []\n",
    "    for data in weather:\n",
    "        info[loc].append(data)\n",
    "print(info)\n",
    "\n",
    "with open('C:/Temp/forecast.txt', \"wt\", encoding=\"utf-8\") as f:\n",
    "    for loc in sorted(info.keys()):\n",
    "        f.write(str(loc)+'\\n')\n",
    "        for name in info[loc]:\n",
    "            f.write('\\t'+str(name)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib.request\n",
    "\n",
    "#User-Agent를 조작하는 경우 \n",
    "hdr = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '+ \n",
    "        'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.80 Safari/537.36'}\n",
    "\n",
    "req = urllib.request.Request('http://unico2013.dothome.co.kr/crawling/header.php', headers = hdr)\n",
    "#req = urllib.request.Request('http://unico2013.dothome.co.kr/crawling/header.php')\n",
    "data = urllib.request.urlopen(req).read()\n",
    "print(data)\n",
    "page = data.decode('utf-8', 'ignore')\n",
    "print(page)\n",
    "res_content = json.loads(data)\n",
    "\n",
    "print(res_content[\"result\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydatavenv",
   "language": "python",
   "name": "pydatavenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
